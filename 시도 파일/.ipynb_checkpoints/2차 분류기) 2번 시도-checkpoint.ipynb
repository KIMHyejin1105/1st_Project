{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f3292ec5-0d88-44d9-9e63-4b69007aaf80",
   "metadata": {},
   "source": [
    "# 2번 군집 데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aa1377f-a653-4762-a26c-768e481dc88c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9db2935-30a2-4f50-8cf7-dad7e9568c1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 1. 데이터 불러오기\n",
    "df = pd.read_csv(\"./dataset/cluster1_2.csv\")\n",
    "\n",
    "df['TIMESTAMP'] = pd.to_datetime(df['TIMESTAMP'])\n",
    "df = df.sort_values(by=['VSL_ID', 'PORT_NAME', 'TIMESTAMP']).reset_index(drop=True)\n",
    "\n",
    "# 결과 저장 리스트\n",
    "rows_5h = []\n",
    "\n",
    "# 30번째 시점 추출 (10분 단위 × 30 = 5시간)\n",
    "for (vsl_id, port), group in df.groupby(['VSL_ID', 'PORT_NAME']):\n",
    "    if len(group) >= 30:\n",
    "        row_5h = group.iloc[29]  # 인덱스는 0부터 시작이므로 29번째가 30번째 행\n",
    "        rows_5h.append(row_5h)\n",
    "\n",
    "# 최종 데이터프레임\n",
    "df_5h = pd.DataFrame(rows_5h).reset_index(drop=True)\n",
    "print(df_5h.shape)\n",
    "display(df_5h.head())\n",
    "display(df_5h['PORT_NAME'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcc64e45-2e40-4bb3-bcb8-319eda015d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_5h.to_csv('./dataset/df_5h_extracted.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2162f324-b0ba-4102-a139-1dc829e56aea",
   "metadata": {},
   "source": [
    "# ✅ Oversampling + XGBoost + RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee65cf03-06ca-4eb0-bd83-7455bbaf1620",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== 1. 라이브러리 =====\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.utils import resample\n",
    "\n",
    "# ===== 3. 라벨 인코딩 =====\n",
    "features = [\"LAT\", \"LON\", \"COG\", \"HEADING\"]\n",
    "X = df_5h[features]\n",
    "y = df_5h[\"PORT_NAME\"]\n",
    "le = LabelEncoder()\n",
    "y_encoded = le.fit_transform(y)\n",
    "df_5h[\"label\"] = y_encoded\n",
    "\n",
    "# ===== 4. 오버샘플링 적용 =====\n",
    "max_count = df_5h[\"label\"].value_counts().max()\n",
    "resampled = []\n",
    "\n",
    "for label in df_5h[\"label\"].unique():\n",
    "    subset = df_5h[df_5h[\"label\"] == label]\n",
    "    upsampled = resample(subset, replace=True, n_samples=max_count, random_state=42)\n",
    "    resampled.append(upsampled)\n",
    "\n",
    "df_balanced = pd.concat(resampled)\n",
    "\n",
    "# ===== 5. 학습/테스트 분리 =====\n",
    "X_bal = df_balanced[features]\n",
    "y_bal = df_balanced[\"label\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_bal, y_bal, test_size=0.2, stratify=y_bal, random_state=42\n",
    ")\n",
    "\n",
    "np.save(\"datasets/X_train_cluster2.npy\", X_train)\n",
    "np.save(\"datasets/X_test_cluster2.npy\", X_test)\n",
    "np.save(\"datasets/y_train_cluster2.npy\", y_train)\n",
    "np.save(\"datasets/y_test_cluster2.npy\", y_test)\n",
    "\n",
    "# ===== 0. 데이터 수 출력 =====\n",
    "print(\"\\n📦 [데이터 개수]\")\n",
    "print(f\"Train: {len(X_train)}개\")\n",
    "print(f\"Test : {len(X_test)}개\")\n",
    "print(f\"전체 : {len(X_train) + len(X_test)}개\")\n",
    "\n",
    "# ===== 6. 모델 정의 및 학습 (하이퍼파라미터 조정 포함) =====\n",
    "rf = RandomForestClassifier(\n",
    "    class_weight='balanced',\n",
    "    n_estimators=100,\n",
    "    max_depth=7,                 # 깊이 제한\n",
    "    min_samples_leaf=3,          # 최소 샘플 수 제한\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "xgb = XGBClassifier(\n",
    "    n_estimators=50,\n",
    "    max_depth=4,                 # 깊이 제한 (기존 5 → 4)\n",
    "    learning_rate=0.05,          # 학습률 낮춤\n",
    "    reg_alpha=0.1,               # L1 규제\n",
    "    reg_lambda=1.0,              # L2 규제\n",
    "    use_label_encoder=False,\n",
    "    eval_metric='mlogloss',\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "voting_clf = VotingClassifier(\n",
    "    estimators=[('rf', rf), ('xgb', xgb)],\n",
    "    voting='soft'\n",
    ")\n",
    "\n",
    "voting_clf.fit(X_train, y_train)\n",
    "\n",
    "# ===== 7. 평가 =====\n",
    "y_pred = voting_clf.predict(X_test)\n",
    "print(classification_report(y_test, y_pred, target_names=le.classes_))\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ===== 1. 교차검증 정확도 =====\n",
    "acc_scores = cross_val_score(voting_clf, X_train, y_train, cv=5, scoring='accuracy')\n",
    "f1_scores = cross_val_score(voting_clf, X_train, y_train, cv=5, scoring='f1_macro')\n",
    "prec_scores = cross_val_score(voting_clf, X_train, y_train, cv=5, scoring='precision_macro')\n",
    "\n",
    "# ===== 2. 학습/테스트 정확도 =====\n",
    "train_score = voting_clf.score(X_train, y_train)\n",
    "test_score = voting_clf.score(X_test, y_test)\n",
    "gap = train_score - test_score\n",
    "\n",
    "# ===== 3. 예측 및 리포트 =====\n",
    "y_pred = voting_clf.predict(X_test)\n",
    "report = classification_report(y_test, y_pred, target_names=le.classes_)\n",
    "\n",
    "# ===== 4. Confusion Matrix =====\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=le.classes_)\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "disp.plot(ax=ax, xticks_rotation=90)\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.grid(False)\n",
    "plt.show()\n",
    "\n",
    "# ===== 5. 결과 출력 =====\n",
    "print(\"📊 [교차검증 결과]\")\n",
    "print(f\"Accuracy (Train): {train_score:.4f}\")\n",
    "print(f\"Accuracy (Test): {test_score:.4f}\")\n",
    "print(f\"CV Accuracy Mean: {acc_scores.mean():.4f} ± {acc_scores.std():.4f}\")\n",
    "print(f\"CV F1 Macro: {f1_scores.mean():.4f}\")\n",
    "print(f\"CV Precision Macro: {prec_scores.mean():.4f}\")\n",
    "if gap > 0.1:\n",
    "    print(f\"⚠️ 과적합 의심: 학습/테스트 정확도 차이 {gap:.4f}\")\n",
    "else:\n",
    "    print(\"✅ 과적합 위험 없음\")\n",
    "\n",
    "print(\"\\n📄 [Classification Report]\")\n",
    "print(report)\n",
    "\n",
    "# ===== 5. 결과 출력 =====\n",
    "print(\"\\n📊 [교차검증 및 과적합 점검 결과]\")\n",
    "print(f\"학습 정확도              : {train_score:.4f}\")\n",
    "print(f\"테스트 정확도            : {test_score:.4f}\")\n",
    "print(f\"정확도 차이              : {gap:.4f} {'⚠️ 과적합 의심' if gap > 0.1 else '과적합 위험 없음'}\")\n",
    "print(f\"교차검증 평균 정확도     : {acc_scores.mean():.4f} ± {acc_scores.std():.4f}\")\n",
    "print(f\"교차검증 F1 매크로 평균  : {f1_scores.mean():.4f}\")\n",
    "print(f\"교차검증 정밀도 평균     : {prec_scores.mean():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a1eed17-4d3b-4cab-aed8-d20a3153429e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 오버샘플링된 레이블 → 항구명으로 다시 복원\n",
    "df_balanced[\"PORT_NAME\"] = le.inverse_transform(df_balanced[\"label\"])\n",
    "\n",
    "# 항구별 데이터 개수 출력\n",
    "print(\"\\n🛳️ [오버샘플링된 항구별 샘플 개수]\")\n",
    "print(df_balanced[\"PORT_NAME\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86f65921-129e-41b6-ba71-2d17ce597225",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# ===== [1] RandomForest 복잡도 분석 =====\n",
    "rf_model = voting_clf.named_estimators_[\"rf\"]\n",
    "tree_depths = [estimator.tree_.max_depth for estimator in rf_model.estimators_]\n",
    "\n",
    "print(\"\\n🌲 RandomForest 복잡도 정보\")\n",
    "print(f\"- 트리 개수         : {len(tree_depths)}\")\n",
    "print(f\"- 평균 깊이         : {np.mean(tree_depths):.2f}\")\n",
    "print(f\"- 최대 깊이         : {np.max(tree_depths)}\")\n",
    "print(f\"- 최소 깊이         : {np.min(tree_depths)}\")\n",
    "\n",
    "# ===== [2] XGBoost 복잡도 분석 =====\n",
    "xgb_model = voting_clf.named_estimators_[\"xgb\"]\n",
    "booster = xgb_model.get_booster()\n",
    "trees = booster.get_dump()\n",
    "\n",
    "print(\"\\n🔥 XGBoost 복잡도 정보\")\n",
    "print(f\"- 트리 개수         : {len(trees)}\")\n",
    "print(f\"- 설정된 max_depth  : {xgb.max_depth}\")\n",
    "\n",
    "# ===== [3] VotingClassifier 구성 확인 =====\n",
    "print(\"\\n🧠 VotingClassifier 구성 모델:\")\n",
    "for name, model in voting_clf.named_estimators_.items():\n",
    "    print(f\"- {name}: {type(model).__name__}\")\n",
    "\n",
    "# ===== [4] Accuracy Gap (= 복잡도 간접 지표) =====\n",
    "gap = train_score - test_score\n",
    "print(f\"\\n📉 Accuracy Gap (과적합 지표): {gap:.4f}\")\n",
    "if gap > 0.1:\n",
    "    print(\"⚠️ 과적합 위험 → 복잡도 높음\")\n",
    "else:\n",
    "    print(\"✅ 과적합 위험 없음 → 복잡도 적절\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de369762-3838-4284-880e-be3a6164e254",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import os\n",
    "\n",
    "# 모델 저장\n",
    "joblib.dump(voting_clf, 'model/port_model_2.joblib')\n",
    "\n",
    "# 인코더 저장\n",
    "joblib.dump(le, 'model/encoder_2.joblib')\n",
    "\n",
    "print(\"✅ 모델과 인코더가 각각 저장되었습니다.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
