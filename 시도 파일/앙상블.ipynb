{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a498d384-8eab-4d0a-b28c-d516bbd693ea",
   "metadata": {},
   "source": [
    "# 포트별 DESTINATION 예측 (Soft Voting 앙상블)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c7ebcf79-95dd-4953-b82d-84708fff459e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69f5e8ff-9c45-44ba-b805-e5def270ff97",
   "metadata": {},
   "source": [
    "## 1. 전처리 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "07988f5f-5d3a-47eb-aeaa-22200a170238",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_destination(dest):\n",
    "    if isinstance(dest, str):\n",
    "        return re.sub(r'\\s+', '', dest.strip().upper())\n",
    "    return dest\n",
    "\n",
    "def create_sequences(data, seq_length, feature_cols, label_col):\n",
    "    X, y = [], []\n",
    "    for i in range(len(data) - seq_length):\n",
    "        seq = data[feature_cols].iloc[i:i+seq_length].values\n",
    "        target = data[label_col].iloc[i+seq_length]\n",
    "        X.append(seq)\n",
    "        y.append(target)\n",
    "    return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f00233a-a017-42e5-b841-34f694b60c99",
   "metadata": {},
   "source": [
    "## 2. 데이터 로딩 및 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "391a1d91-1895-4a71-8baa-33fcfc1e4185",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./datasets/all_merged.csv\")\n",
    "df[\"DESTINATION\"] = df[\"DESTINATION\"].apply(clean_destination)\n",
    "df = df.dropna(subset=[\"DESTINATION\"])\n",
    "\n",
    "# 전체 DESTINATION에 대해 인코딩\n",
    "le_global = LabelEncoder()\n",
    "df[\"DEST_LABEL\"] = le_global.fit_transform(df[\"DESTINATION\"])\n",
    "num_classes = len(le_global.classes_)\n",
    "\n",
    "# 사용할 feature 목록\n",
    "feature_cols = [\"SPEED\", \"COG\", \"HEADING\", \"DRAFT\", \"LAT\", \"LON\"]\n",
    "seq_length = 10\n",
    "\n",
    "# 예측 가능한 포트만 필터링\n",
    "valid_ports = df.groupby(\"PORT_NAME\")[\"DEST_LABEL\"].nunique()\n",
    "valid_ports = valid_ports[valid_ports > 1].index.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba249233-9c1a-4ce5-94d2-fe62e8011778",
   "metadata": {},
   "source": [
    "## 3. 포트별 LSTM + RF 앙상블 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c1cee755-918c-4c20-a4e6-149db37b2d95",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "ensemble_results = {}\n",
    "\n",
    "for port in valid_ports:\n",
    "    port_df = df[df[\"PORT_NAME\"] == port].copy()\n",
    "    if len(port_df) < seq_length + 10:\n",
    "        continue\n",
    "\n",
    "    port_df = port_df.sort_values(\"TIMESTAMP\")\n",
    "    port_df[\"DEST_LABEL\"] = le_global.transform(port_df[\"DESTINATION\"])  # 동일한 인코더 사용\n",
    "\n",
    "    # 스케일링\n",
    "    scaler = MinMaxScaler()\n",
    "    port_df[feature_cols] = scaler.fit_transform(port_df[feature_cols])\n",
    "\n",
    "    # 시퀀스 생성\n",
    "    X_seq, y_seq = create_sequences(port_df, seq_length, feature_cols, \"DEST_LABEL\")\n",
    "    if len(np.unique(y_seq)) < 2:\n",
    "        continue\n",
    "\n",
    "    # RF 입력용: 마지막 타임스텝\n",
    "    X_rf = X_seq[:, -1, :]\n",
    "    split = int(len(X_seq) * 0.8)\n",
    "    X_train_seq, X_test_seq = X_seq[:split], X_seq[split:]\n",
    "    X_train_rf, X_test_rf = X_rf[:split], X_rf[split:]\n",
    "    y_train, y_test = y_seq[:split], y_seq[split:]\n",
    "\n",
    "    # LSTM 모델 정의\n",
    "    model_lstm = Sequential([\n",
    "        LSTM(64, input_shape=(seq_length, len(feature_cols))),\n",
    "        Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    model_lstm.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    model_lstm.fit(X_train_seq, y_train, epochs=5, batch_size=64, verbose=0)\n",
    "    y_pred_lstm_proba = model_lstm.predict(X_test_seq, verbose=0)\n",
    "\n",
    "    # 랜덤 포레스트 모델\n",
    "    model_rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    model_rf.fit(X_train_rf, y_train)\n",
    "    y_pred_rf_proba = model_rf.predict_proba(X_test_rf)\n",
    "\n",
    "    # soft voting 앙상블\n",
    "    min_len = min(y_pred_lstm_proba.shape[1], y_pred_rf_proba.shape[1])\n",
    "    avg_proba = (y_pred_lstm_proba[:, :min_len] + y_pred_rf_proba[:, :min_len]) / 2\n",
    "    y_pred_ensemble = np.argmax(avg_proba, axis=1)\n",
    "\n",
    "    # 정확도 저장\n",
    "    acc = accuracy_score(y_test, y_pred_ensemble)\n",
    "    ensemble_results[port] = round(acc, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a1e76cf-313b-4e17-9ef8-be6fc8eefbd2",
   "metadata": {},
   "source": [
    "## 4. 결과 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1904db1a-a644-47d1-8538-dfbdf8b2403c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   PORT_NAME  Ensemble_Accuracy\n",
      "7      CNSHA             0.0005\n",
      "0      CNDAG             0.0000\n",
      "39     KRMAS             0.0000\n",
      "29     JPTYO             0.0000\n",
      "30     JPUKB             0.0000\n",
      "31     JPWAK             0.0000\n",
      "32     JPYKK             0.0000\n",
      "33     JPYOK             0.0000\n",
      "34     KRBNP             0.0000\n",
      "35     KRINC             0.0000\n",
      "36     KRKAN             0.0000\n",
      "37     KRKCN             0.0000\n",
      "38     KRKPO             0.0000\n",
      "40     KRPTK             0.0000\n",
      "27     JPSMZ             0.0000\n",
      "41     KRUSN             0.0000\n",
      "42     KRYOS             0.0000\n",
      "43     PHMNL             0.0000\n",
      "44     RUNJK             0.0000\n",
      "45     RUVVO             0.0000\n",
      "46     TWKEL             0.0000\n",
      "47     TWKHH             0.0000\n",
      "48     TWTPE             0.0000\n",
      "49     VNCLI             0.0000\n",
      "50     VNHPH             0.0000\n",
      "28     JPTOS             0.0000\n",
      "26     JPSDJ             0.0000\n",
      "1      CNHUA             0.0000\n",
      "13     JPHKT             0.0000\n",
      "2      CNLYG             0.0000\n",
      "3      CNNGB             0.0000\n",
      "4      CNNJI             0.0000\n",
      "5      CNQDG             0.0000\n",
      "6      CNRZH             0.0000\n",
      "8      CNTAC             0.0000\n",
      "9      CNTXG             0.0000\n",
      "10     HKHKG             0.0000\n",
      "11     JPFKY             0.0000\n",
      "12     JPHIJ             0.0000\n",
      "14     JPIMB             0.0000\n",
      "25     JPSBS             0.0000\n",
      "15     JPIMI             0.0000\n",
      "16     JPKIJ             0.0000\n",
      "17     JPKNZ             0.0000\n",
      "18     JPMIZ             0.0000\n",
      "19     JPMKX             0.0000\n",
      "20     JPMOJ             0.0000\n",
      "21     JPNGO             0.0000\n",
      "22     JPNGS             0.0000\n",
      "23     JPONA             0.0000\n",
      "24     JPOSA             0.0000\n",
      "51     VNSGN             0.0000\n"
     ]
    }
   ],
   "source": [
    "result_df = pd.DataFrame(ensemble_results.items(), columns=[\"PORT_NAME\", \"Ensemble_Accuracy\"])\n",
    "print(result_df.sort_values(by=\"Ensemble_Accuracy\", ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fdbbe1af-d429-4370-8835-d239464c3d4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "This solver needs samples of at least 2 classes in the data, but the data contains only one class: 130",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[27], line 91\u001b[0m\n\u001b[0;32m     89\u001b[0m \u001b[38;5;66;03m# (4) 메타 모델 학습 및 예측\u001b[39;00m\n\u001b[0;32m     90\u001b[0m meta_model \u001b[38;5;241m=\u001b[39m LogisticRegression(max_iter\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1000\u001b[39m)\n\u001b[1;32m---> 91\u001b[0m meta_model\u001b[38;5;241m.\u001b[39mfit(X_meta, y_test)\n\u001b[0;32m     92\u001b[0m y_pred_stacked \u001b[38;5;241m=\u001b[39m meta_model\u001b[38;5;241m.\u001b[39mpredict(X_meta)\n\u001b[0;32m     94\u001b[0m \u001b[38;5;66;03m# (5) 정확도 저장\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1471\u001b[0m     )\n\u001b[0;32m   1472\u001b[0m ):\n\u001b[1;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1301\u001b[0m, in \u001b[0;36mLogisticRegression.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m   1299\u001b[0m classes_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_\n\u001b[0;32m   1300\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_classes \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[1;32m-> 1301\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1302\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis solver needs samples of at least 2 classes\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1303\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m in the data, but the data contains only one\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1304\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m class: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m classes_[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m   1305\u001b[0m     )\n\u001b[0;32m   1307\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[0;32m   1308\u001b[0m     n_classes \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "\u001b[1;31mValueError\u001b[0m: This solver needs samples of at least 2 classes in the data, but the data contains only one class: 130"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "\n",
    "# ----------------------- #\n",
    "# 전처리 함수\n",
    "# ----------------------- #\n",
    "def clean_destination(dest):\n",
    "    if isinstance(dest, str):\n",
    "        return re.sub(r'\\s+', '', dest.strip().upper())\n",
    "    return dest\n",
    "\n",
    "def create_sequences(data, seq_length, feature_cols, label_col):\n",
    "    X, y = [], []\n",
    "    for i in range(len(data) - seq_length):\n",
    "        seq = data[feature_cols].iloc[i:i+seq_length].values\n",
    "        target = data[label_col].iloc[i+seq_length]\n",
    "        X.append(seq)\n",
    "        y.append(target)\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "# ----------------------- #\n",
    "# 데이터 준비\n",
    "# ----------------------- #\n",
    "df = pd.read_csv(\"./datasets/all_merged.csv\")\n",
    "df[\"DESTINATION\"] = df[\"DESTINATION\"].apply(clean_destination)\n",
    "df = df.dropna(subset=[\"DESTINATION\"])\n",
    "\n",
    "le_global = LabelEncoder()\n",
    "df[\"DEST_LABEL\"] = le_global.fit_transform(df[\"DESTINATION\"])\n",
    "num_classes = len(le_global.classes_)\n",
    "\n",
    "feature_cols = [\"SPEED\", \"COG\", \"HEADING\", \"DRAFT\", \"LAT\", \"LON\"]\n",
    "seq_length = 10\n",
    "\n",
    "valid_ports = df.groupby(\"PORT_NAME\")[\"DEST_LABEL\"].nunique()\n",
    "valid_ports = valid_ports[valid_ports > 1].index.tolist()\n",
    "\n",
    "# ----------------------- #\n",
    "# 포트별 Stacking 앙상블\n",
    "# ----------------------- #\n",
    "stacking_results = {}\n",
    "\n",
    "for port in valid_ports:\n",
    "    port_df = df[df[\"PORT_NAME\"] == port].copy()\n",
    "    if len(port_df) < seq_length + 10:\n",
    "        continue\n",
    "\n",
    "    port_df = port_df.sort_values(\"TIMESTAMP\")\n",
    "    port_df[\"DEST_LABEL\"] = le_global.transform(port_df[\"DESTINATION\"])\n",
    "\n",
    "    scaler = MinMaxScaler()\n",
    "    port_df[feature_cols] = scaler.fit_transform(port_df[feature_cols])\n",
    "\n",
    "    X_seq, y_seq = create_sequences(port_df, seq_length, feature_cols, \"DEST_LABEL\")\n",
    "    if len(np.unique(y_seq)) < 2:\n",
    "        continue\n",
    "\n",
    "    X_rf = X_seq[:, -1, :]\n",
    "    split = int(len(X_seq) * 0.8)\n",
    "    X_train_seq, X_test_seq = X_seq[:split], X_seq[split:]\n",
    "    X_train_rf, X_test_rf = X_rf[:split], X_rf[split:]\n",
    "    y_train, y_test = y_seq[:split], y_seq[split:]\n",
    "\n",
    "    # (1) LSTM 학습\n",
    "    model_lstm = Sequential([\n",
    "        LSTM(64, input_shape=(seq_length, len(feature_cols))),\n",
    "        Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    model_lstm.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    model_lstm.fit(X_train_seq, y_train, epochs=5, batch_size=64, verbose=0)\n",
    "    y_pred_lstm_proba = model_lstm.predict(X_test_seq, verbose=0)\n",
    "\n",
    "    # (2) RandomForest 학습\n",
    "    model_rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    model_rf.fit(X_train_rf, y_train)\n",
    "    y_pred_rf_proba = model_rf.predict_proba(X_test_rf)\n",
    "\n",
    "    # (3) Stacking feature 생성\n",
    "    min_len = min(y_pred_lstm_proba.shape[1], y_pred_rf_proba.shape[1])\n",
    "    X_meta = np.hstack([y_pred_lstm_proba[:, :min_len], y_pred_rf_proba[:, :min_len]])\n",
    "\n",
    "    # (4) 메타 모델 학습 및 예측\n",
    "    meta_model = LogisticRegression(max_iter=1000)\n",
    "    meta_model.fit(X_meta, y_test)\n",
    "    y_pred_stacked = meta_model.predict(X_meta)\n",
    "\n",
    "    # (5) 정확도 저장\n",
    "    acc = accuracy_score(y_test, y_pred_stacked)\n",
    "    stacking_results[port] = round(acc, 4)\n",
    "\n",
    "# ----------------------- #\n",
    "# 결과 출력\n",
    "# ----------------------- #\n",
    "result_df = pd.DataFrame(stacking_results.items(), columns=[\"PORT_NAME\", \"Stacking_Accuracy\"])\n",
    "print(result_df.sort_values(by=\"Stacking_Accuracy\", ascending=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "39c15852-f28f-438c-b11e-8324217e0ce9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_test unique values: [127 207]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "y contains previously unseen labels: 670",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_encode.py:225\u001b[0m, in \u001b[0;36m_encode\u001b[1;34m(values, uniques, check_unknown)\u001b[0m\n\u001b[0;32m    224\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 225\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _map_to_integer(values, uniques)\n\u001b[0;32m    226\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_encode.py:165\u001b[0m, in \u001b[0;36m_map_to_integer\u001b[1;34m(values, uniques)\u001b[0m\n\u001b[0;32m    164\u001b[0m table \u001b[38;5;241m=\u001b[39m _nandict({val: i \u001b[38;5;28;01mfor\u001b[39;00m i, val \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(uniques)})\n\u001b[1;32m--> 165\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray([table[v] \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m values])\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_encode.py:159\u001b[0m, in \u001b[0;36m_nandict.__missing__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    158\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnan_value\n\u001b[1;32m--> 159\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 670",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[35], line 93\u001b[0m\n\u001b[0;32m     90\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_test unique values: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnp\u001b[38;5;241m.\u001b[39munique(y_test)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)  \u001b[38;5;66;03m# y_test의 유니크 값 확인\u001b[39;00m\n\u001b[0;32m     92\u001b[0m \u001b[38;5;66;03m# y_test가 잘못된 클래스를 포함하면, 다시 라벨 인코딩\u001b[39;00m\n\u001b[1;32m---> 93\u001b[0m y_train_cleaned \u001b[38;5;241m=\u001b[39m le_global\u001b[38;5;241m.\u001b[39mtransform(y_train)\n\u001b[0;32m     94\u001b[0m y_test_cleaned \u001b[38;5;241m=\u001b[39m le_global\u001b[38;5;241m.\u001b[39mtransform(y_test)\n\u001b[0;32m     96\u001b[0m \u001b[38;5;66;03m# (5) XGBoost 메타 모델 학습\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:137\u001b[0m, in \u001b[0;36mLabelEncoder.transform\u001b[1;34m(self, y)\u001b[0m\n\u001b[0;32m    134\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _num_samples(y) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    135\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray([])\n\u001b[1;32m--> 137\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _encode(y, uniques\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_encode.py:227\u001b[0m, in \u001b[0;36m_encode\u001b[1;34m(values, uniques, check_unknown)\u001b[0m\n\u001b[0;32m    225\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m _map_to_integer(values, uniques)\n\u001b[0;32m    226\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m--> 227\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my contains previously unseen labels: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(e)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    228\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    229\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m check_unknown:\n",
      "\u001b[1;31mValueError\u001b[0m: y contains previously unseen labels: 670"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import xgboost as xgb\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "\n",
    "# ----------------------- #\n",
    "# 전처리 함수\n",
    "# ----------------------- #\n",
    "def clean_destination(dest):\n",
    "    if isinstance(dest, str):\n",
    "        return re.sub(r'\\s+', '', dest.strip().upper())\n",
    "    return dest\n",
    "\n",
    "def create_sequences(data, seq_length, feature_cols, label_col):\n",
    "    X, y = [], []\n",
    "    for i in range(len(data) - seq_length):\n",
    "        seq = data[feature_cols].iloc[i:i+seq_length].values\n",
    "        target = data[label_col].iloc[i+seq_length]\n",
    "        X.append(seq)\n",
    "        y.append(target)\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "# ----------------------- #\n",
    "# 데이터 준비\n",
    "# ----------------------- #\n",
    "df = pd.read_csv(\"./datasets/all_merged.csv\")\n",
    "df[\"DESTINATION\"] = df[\"DESTINATION\"].apply(clean_destination)\n",
    "df = df.dropna(subset=[\"DESTINATION\"])\n",
    "\n",
    "le_global = LabelEncoder()\n",
    "df[\"DEST_LABEL\"] = le_global.fit_transform(df[\"DESTINATION\"])\n",
    "num_classes = len(le_global.classes_)\n",
    "\n",
    "feature_cols = [\"SPEED\", \"COG\", \"HEADING\", \"DRAFT\", \"LAT\", \"LON\"]\n",
    "seq_length = 10\n",
    "\n",
    "valid_ports = df.groupby(\"PORT_NAME\")[\"DEST_LABEL\"].nunique()\n",
    "valid_ports = valid_ports[valid_ports > 1].index.tolist()\n",
    "\n",
    "# ----------------------- #\n",
    "# 포트별 LSTM + XGBoost Stacking 앙상블\n",
    "# ----------------------- #\n",
    "stacking_results_xgb = {}\n",
    "\n",
    "for port in valid_ports:\n",
    "    port_df = df[df[\"PORT_NAME\"] == port].copy()\n",
    "    if len(port_df) < seq_length + 10:\n",
    "        continue\n",
    "\n",
    "    port_df = port_df.sort_values(\"TIMESTAMP\")\n",
    "    port_df[\"DEST_LABEL\"] = le_global.transform(port_df[\"DESTINATION\"])\n",
    "\n",
    "    scaler = MinMaxScaler()\n",
    "    port_df[feature_cols] = scaler.fit_transform(port_df[feature_cols])\n",
    "\n",
    "    X_seq, y_seq = create_sequences(port_df, seq_length, feature_cols, \"DEST_LABEL\")\n",
    "    if len(np.unique(y_seq)) < 2:\n",
    "        continue\n",
    "\n",
    "    X_rf = X_seq[:, -1, :]\n",
    "    split = int(len(X_seq) * 0.8)\n",
    "    X_train_seq, X_test_seq = X_seq[:split], X_seq[split:]\n",
    "    X_train_rf, X_test_rf = X_rf[:split], X_rf[split:]\n",
    "    y_train, y_test = y_seq[:split], y_seq[split:]\n",
    "\n",
    "    # (1) LSTM 모델 학습\n",
    "    model_lstm = Sequential([\n",
    "        LSTM(64, input_shape=(seq_length, len(feature_cols))),\n",
    "        Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    model_lstm.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    model_lstm.fit(X_train_seq, y_train, epochs=5, batch_size=64, verbose=0)\n",
    "    y_pred_lstm_proba = model_lstm.predict(X_test_seq, verbose=0)\n",
    "\n",
    "    # (2) RandomForest 모델 학습\n",
    "    model_rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    model_rf.fit(X_train_rf, y_train)\n",
    "    y_pred_rf_proba = model_rf.predict_proba(X_test_rf)\n",
    "\n",
    "    # (3) Stacking feature 생성\n",
    "    min_len = min(y_pred_lstm_proba.shape[1], y_pred_rf_proba.shape[1])\n",
    "    X_meta = np.hstack([y_pred_lstm_proba[:, :min_len], y_pred_rf_proba[:, :min_len]])\n",
    "\n",
    "    # (4) y_test 값 확인 및 정리\n",
    "    print(f\"y_test unique values: {np.unique(y_test)}\")  # y_test의 유니크 값 확인\n",
    "\n",
    "    # y_test가 잘못된 클래스를 포함하면, 다시 라벨 인코딩\n",
    "    y_train_cleaned = le_global.transform(y_train)\n",
    "    y_test_cleaned = le_global.transform(y_test)\n",
    "\n",
    "    # (5) XGBoost 메타 모델 학습\n",
    "    meta_model_xgb = xgb.XGBClassifier(objective=\"multi:softmax\", num_class=num_classes, random_state=42)\n",
    "    meta_model_xgb.fit(X_meta, y_test_cleaned)\n",
    "    y_pred_stacked_xgb = meta_model_xgb.predict(X_meta)\n",
    "\n",
    "    # (6) 정확도 저장\n",
    "    acc = accuracy_score(y_test_cleaned, y_pred_stacked_xgb)\n",
    "    stacking_results_xgb[port] = round(acc, 4)\n",
    "\n",
    "# 결과 출력\n",
    "result_df_xgb = pd.DataFrame(stacking_results_xgb.items(), columns=[\"PORT_NAME\", \"Stacking_XGBoost_Accuracy\"])\n",
    "import ace_tools as tools; tools.display_dataframe_to_user(name=\"XGBoost Stacking 정확도\", dataframe=result_df_xgb.sort_values(by=\"Stacking_XGBoost_Accuracy\", ascending=False))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
