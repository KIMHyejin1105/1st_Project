{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "130f48c0-dbbe-496f-afe3-64b6602f867d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.ensemble import VotingClassifier, RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "import joblib  # ëª¨ë¸ ì €ì¥ìš©\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "640a4cf8-be45-4fe4-8be3-443983cc7cad",
   "metadata": {},
   "source": [
    "# ìµœì¢… !!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "8691c734-f1d5-4b67-b8f5-2ea63978aea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import joblib\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# -----------------------------\n",
    "# êµ°ì§‘ë³„ ëª¨ë¸ ê²½ë¡œ ë° ì¸ì½”ë” ì •ì˜\n",
    "# -----------------------------\n",
    "cluster_model_paths = {\n",
    "    1: {\"model\": \"model/port_c1_17hours.joblib\", \"encoder\": \"model/encoder_c1_17hours.joblib\"},\n",
    "    2: {\"model\": \"model/port_c2_17hours.joblib\", \"encoder\": \"model/encoder_c2_17hours.joblib\"},\n",
    "    3: {\"model\": \"model/port_c3_17hours.joblib\", \"encoder\": \"model/encoder_c3_17hours.joblib\"},\n",
    "    4: {\"model\": \"model/port_c4_17hours.joblib\", \"encoder\": \"model/encoder_c4_17hours.joblib\"},\n",
    "    6: {\"model\": \"model/port_c6_17hours.joblib\", \"encoder\": \"model/encoder_c6_17hours.joblib\"},\n",
    "    7: {\"model\": \"model/port_c7_17hours.joblib\", \"encoder\": \"model/encoder_c7_17hours.joblib\"}\n",
    "}\n",
    "\n",
    "# -----------------------------\n",
    "# êµ°ì§‘ë³„ ê³ ì • ë‹¨ì¼ í•­êµ¬ ë§¤í•‘\n",
    "# -----------------------------\n",
    "fixed_cluster_ports = {\n",
    "    0: \"PHMNL\",\n",
    "    5: \"VNHPH\"\n",
    "}\n",
    "\n",
    "# -----------------------------\n",
    "# ì˜ˆì¸¡ í•¨ìˆ˜\n",
    "# -----------------------------\n",
    "def predict_top_ports_from_input():\n",
    "    # 1. ì‚¬ìš©ì ì…ë ¥\n",
    "    print(\"ğŸš¢ AIS ë°ì´í„° ì…ë ¥ (5ì‹œê°„ ì‹œì  ê¸°ì¤€)\")\n",
    "    try:\n",
    "        lat = float(input(\"LAT (ìœ„ë„): \"))\n",
    "        lon = float(input(\"LON (ê²½ë„): \"))\n",
    "        cog = float(input(\"COG (ì¹¨ë¡œ): \"))\n",
    "        heading = float(input(\"HEADING (ë°©ìœ„ê°): \"))\n",
    "    except ValueError:\n",
    "        print(\"âš ï¸ ìˆ«ìë§Œ ì…ë ¥í•´ì£¼ì„¸ìš”.\")\n",
    "        return\n",
    "\n",
    "    user_input = np.array([[lat, lon, cog, heading]]) # (1, 4) í¬ê¸°ì˜ numpy arrayë¡œ ì €ì¥\n",
    "\n",
    "    # 2. 1ì°¨ êµ°ì§‘ ì˜ˆì¸¡ ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "    try:\n",
    "        cluster_model = joblib.load(\"./model/cluster_17hours.joblib\") #1ì°¨ soft voting ë¶„ë¥˜ê¸°\n",
    "    except FileNotFoundError:\n",
    "        print(\"âŒ 1ì°¨ ë¶„ë¥˜ê¸° ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "        return\n",
    "\n",
    "    # 3. 1ì°¨ êµ°ì§‘ ì˜ˆì¸¡ ë° í™•ë¥ \n",
    "    cluster_probs = cluster_model.predict_proba(user_input)[0] #ê° êµ°ì§‘ì— ì†í•  í™•ë¥  ë°˜í™˜í™˜\n",
    "    cluster_labels = cluster_model.classes_\n",
    "\n",
    "    # 4. í™•ë¥  ë†’ì€ Top-2 êµ°ì§‘ ì¶”ì¶œ\n",
    "    top2_idx = np.argsort(cluster_probs)[-2:][::-1]\n",
    "    print(\"\\nğŸ” [1ì°¨ ë¶„ë¥˜ê¸°] Top-2 êµ°ì§‘:\")\n",
    "    for i in top2_idx:\n",
    "        print(f\" - CLUSTER_{cluster_labels[i]}: {cluster_probs[i]:.2%}\")\n",
    "        \n",
    "    final_probs_joint = {}    # joint í™•ë¥  ê¸°ë°˜ (1ì°¨ êµ°ì§‘ì˜ í™•ë¥  X 2ì°¨ êµ°ì§‘ì˜ í™•ë¥ )\n",
    "    \n",
    "    # 5. ê° Top-2 êµ°ì§‘ì— ëŒ€í•´ 2ì°¨ í•­êµ¬ ì˜ˆì¸¡ ìˆ˜í–‰\n",
    "    for i in top2_idx:\n",
    "        prob_cluster = cluster_probs[i] #í•´ë‹¹ êµ°ì§‘ì´ ì„ íƒë  í™•ë¥ \n",
    "        cluster_id = cluster_labels[i] #í•´ë‹¹ êµ°ì§‘ì˜ ë²ˆí˜¸í˜¸\n",
    "\n",
    "        # 5-1. ê³ ì • ë‹¨ì¼ í•­êµ¬ ì²˜ë¦¬ (ëª¨ë¸ ì—†ì´ ê³ ì •ëœ í•­êµ¬)\n",
    "        if cluster_id in fixed_cluster_ports:\n",
    "            fixed_port = fixed_cluster_ports[cluster_id]\n",
    "            final_probs_joint[fixed_port] = final_probs_joint.get(fixed_port, 0) + prob_cluster\n",
    "            print(f\"ğŸ“¦ êµ°ì§‘ {cluster_id} â†’ ë‹¨ì¼ í•­êµ¬ '{fixed_port}' í™•ë¥  ì ìš©: {prob_cluster:.2%}\")\n",
    "            continue\n",
    "\n",
    "        # 5-2. ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸° ì‹¤íŒ¨ ì‹œ skip\n",
    "        if cluster_id not in cluster_model_paths:\n",
    "            print(f\"âš ï¸ êµ°ì§‘ {cluster_id} ëª¨ë¸ ê²½ë¡œ ë¯¸ì •ì˜\")\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            model = joblib.load(cluster_model_paths[cluster_id][\"model\"])\n",
    "            le = joblib.load(cluster_model_paths[cluster_id][\"encoder\"])\n",
    "        except:\n",
    "            print(f\"âš ï¸ êµ°ì§‘ {cluster_id}ì˜ ëª¨ë¸ ë˜ëŠ” ì¸ì½”ë” ë¡œë”© ì‹¤íŒ¨\")\n",
    "            continue\n",
    "\n",
    "        # 5-3. í•­êµ¬ë³„ ì˜ˆì¸¡ í™•ë¥  ê³„ì‚°\n",
    "        port_probs = model.predict_proba(user_input)[0] #í•´ë‹¹ êµ°ì§‘ì˜ 2ì°¨ í•­êµ¬ ë¶„ë¥˜ê¸°\n",
    "        try:\n",
    "            port_names = le.inverse_transform(np.arange(len(port_probs))) #ê·¸ êµ°ì§‘ì—ì„œ í•™ìŠµëœ LabelEncoder\n",
    "        except:\n",
    "            port_names = model.classes_\n",
    "\n",
    "        # 5-4. Top-2 í•­êµ¬ë§Œ ì¶”ì¶œ JOINT í™•ë¥  (ì¡°ê±´ë¶€ í™•ë¥ )\n",
    "        top2_ports_idx = np.argsort(port_probs)[-2:][::-1]\n",
    "        print(f\"\\nğŸ“ CLUSTER_{cluster_id} ë‚´ Top-2 í•­êµ¬:\")\n",
    "        for j in top2_ports_idx:\n",
    "            port = port_names[j]\n",
    "            prob = port_probs[j]\n",
    "            print(f\" - {port}: {prob:.2%}\")\n",
    "        \n",
    "\n",
    "            # Joint í™•ë¥  = 1ì°¨ êµ°ì§‘ í™•ë¥  Ã— 2ì°¨ í•­êµ¬ í™•ë¥ \n",
    "            joint_prob = prob_cluster * prob #1ì°¨ ë¶„ë¥˜ê¸° í™•ë¥  X 2ì°¨ ë¶„ë¥˜ê¸° í™•ë¥  = í•´ë‹¹ êµ°ì§‘ì´ ì„ íƒë˜ê³ , ê·¸ ì•ˆì—ì„œ í•´ë‹¹ í•­êµ¬ê°€ ë‚˜ì˜¬ í™•ë¥ \n",
    "            final_probs_joint[port] = joint_prob #final_probs_jointë¼ëŠ” ë”•ì…”ë„ˆë¦¬ {port:joint_port}\n",
    "            \n",
    "    # 6. ê²°ê³¼ ì¶œë ¥\n",
    "    if not final_probs_joint:\n",
    "        print(\"â— ì˜ˆì¸¡ ê°€ëŠ¥í•œ í•­êµ¬ê°€ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "        return\n",
    "\n",
    "    # 6-1. Joint í™•ë¥  ê¸°ë°˜ Top-3\n",
    "    # ìµœì¢… joint í™•ë¥  ê¸°ì¤€ top-3 í•­êµ¬ ì¶œë ¥\n",
    "    sorted_joint = sorted(final_probs_joint.items(), key=lambda x: x[1], reverse=True)[:3]\n",
    "    print(\"\\nğŸ”® [Joint í™•ë¥  ê¸°ë°˜] Top-3 í•­êµ¬ ì˜ˆì¸¡ ê²°ê³¼:\")\n",
    "    for port, prob in sorted_joint:\n",
    "       print(f\"ğŸ“¦ {port}: {prob:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4bc61036-3a54-4281-b2cc-3cbe08031e62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš¢ AIS ë°ì´í„° ì…ë ¥ (5ì‹œê°„ ì‹œì  ê¸°ì¤€)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "LAT (ìœ„ë„):  33.93432833\n",
      "LON (ê²½ë„):  132.6795133\n",
      "COG (ì¹¨ë¡œ):  57\n",
      "HEADING (ë°©ìœ„ê°):  55\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ” [1ì°¨ ë¶„ë¥˜ê¸°] Top-2 êµ°ì§‘:\n",
      " - CLUSTER_3: 81.64%\n",
      " - CLUSTER_7: 10.36%\n",
      "\n",
      "ğŸ“ CLUSTER_3 ë‚´ Top-2 í•­êµ¬:\n",
      " - West Japan (JPUKB, JPOSA, JPWAK, JPYKK, JPNGO, JPMKX): 98.18%\n",
      " - East Japan (JPKIJ, JPTYO, JPYOK, JPSMZ): 1.82%\n",
      "\n",
      "ğŸ“ CLUSTER_7 ë‚´ Top-2 í•­êµ¬:\n",
      " - RUVVO: 97.26%\n",
      " - RUNJK: 2.74%\n",
      "\n",
      "ğŸ”® [Joint í™•ë¥  ê¸°ë°˜] Top-3 í•­êµ¬ ì˜ˆì¸¡ ê²°ê³¼:\n",
      "ğŸ“¦ West Japan (JPUKB, JPOSA, JPWAK, JPYKK, JPNGO, JPMKX): 80.16%\n",
      "ğŸ“¦ RUVVO: 10.08%\n",
      "ğŸ“¦ East Japan (JPKIJ, JPTYO, JPYOK, JPSMZ): 1.48%\n"
     ]
    }
   ],
   "source": [
    "predict_top_ports_from_input()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6df24d2f-b072-4f2b-93d8-697c7b7a89cc",
   "metadata": {},
   "source": [
    "# í…ŒìŠ¤íŠ¸ ë°ì´í„°ì…‹ ë³‘í•©"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "26ab84ef-944f-46f3-acbc-b33852cac0d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… merged_dataset_full.csv ì €ì¥ ì™„ë£Œ\n",
      "ğŸ“ ì „ì²´ ìƒ˜í”Œ ìˆ˜: 101, ì»¬ëŸ¼ ìˆ˜: 6\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import joblib\n",
    "\n",
    "# ğŸ“ ê²½ë¡œ ë° ì„¤ì •\n",
    "base_path = \"datasets\"\n",
    "clusters = [1, 2, 3, 4, 6, 7]\n",
    "columns = [\"LAT\", \"LON\", \"COG\", \"HEADING\"]\n",
    "\n",
    "merged_all = []\n",
    "\n",
    "for cluster_id in clusters:\n",
    "    x_path = os.path.join(base_path, f\"X_test_c{cluster_id}_17hours.npy\")\n",
    "    y_path = os.path.join(base_path, f\"y_test_c{cluster_id}_17hours.npy\")\n",
    "    encoder_path = f\"model/encoder_c{cluster_id}_17hours.joblib\"\n",
    "   \n",
    "    if os.path.exists(x_path) and os.path.exists(y_path):\n",
    "        X = np.load(x_path)\n",
    "        y = np.load(y_path, allow_pickle=True)\n",
    "\n",
    "        # ğŸ” êµ°ì§‘ë³„ ì¸ì½”ë” ë¡œë“œ (ìˆ«ìë¼ë©´ ì—­ë³€í™˜)\n",
    "        if isinstance(y[0], (int, np.integer)):\n",
    "            if os.path.exists(encoder_path):\n",
    "                le = joblib.load(encoder_path)\n",
    "                y = le.inverse_transform(y)\n",
    "            else:\n",
    "                print(f\"âš ï¸ ì¸ì½”ë” ì—†ìŒ: {encoder_path}\")\n",
    "        \n",
    "        # ğŸ”§ DataFrame êµ¬ì„±\n",
    "        df = pd.DataFrame(X, columns=columns)\n",
    "        df[\"CLUSTER_ID\"] = cluster_id\n",
    "        df[\"PORT_NAME\"] = y  # ë¬¸ìì—´ í•­êµ¬ëª…ìœ¼ë¡œ ë³µì›ë¨\n",
    "\n",
    "        merged_all.append(df)\n",
    "    else:\n",
    "        print(f\"âš ï¸ cluster {cluster_id} íŒŒì¼ ëˆ„ë½: {x_path} or {y_path}\")\n",
    "\n",
    "# ğŸ”„ ì „ì²´ ë³‘í•©\n",
    "final_df = pd.concat(merged_all, ignore_index=True)\n",
    "\n",
    "# âœ… ì €ì¥\n",
    "final_df.to_csv(\"test_17h_datasets.csv\", index=False)\n",
    "\n",
    "print(\"âœ… merged_dataset_full.csv ì €ì¥ ì™„ë£Œ\")\n",
    "print(f\"ğŸ“ ì „ì²´ ìƒ˜í”Œ ìˆ˜: {final_df.shape[0]}, ì»¬ëŸ¼ ìˆ˜: {final_df.shape[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32b9b1aa-df19-47a2-804e-cf59ed570139",
   "metadata": {},
   "source": [
    "# top-1 ì •í™•ë„ + top-3 í¬í•¨ë¥ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "89052508-8794-4c57-9e11-957ee6e048e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“Š 17ì‹œê°„ í‰ê°€ ê²°ê³¼\n",
      "ì „ì²´ ìƒ˜í”Œ ìˆ˜: 101\n",
      "ğŸ¯ Top-1 ì •í™•ë„: 41.58%\n",
      "ğŸ¯ Top-3 í¬í•¨ë¥ : 63.37%\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# ğŸš¢ í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "df = pd.read_csv(\"test_17h_datasets.csv\")  # ì»¬ëŸ¼: LAT, LON, COG, HEADING, CLUSTER_ID, PORT_NAME\n",
    "\n",
    "# ğŸ¯ í‰ê°€ ì§€í‘œ ì €ì¥\n",
    "top1_correct = 0 #top-1 ì •í™•ë„ ì¹´ìš´íŠ¸\n",
    "top3_correct = 0 #top-3 í¬í•¨ë¥  ì¹´ìš´íŠ¸\n",
    "total = len(df) #ì „ì²´ ìƒ˜í”Œ ìˆ˜\n",
    "\n",
    "for i, row in df.iterrows():\n",
    "    # ì…ë ¥ê°’ ì¤€ë¹„ (5ì‹œê°„ ì‹œì ì˜ ìœ„ì¹˜, ì½”ê·¸, í—¤ë”©)\n",
    "    user_input = np.array([[row[\"LAT\"], row[\"LON\"], row[\"COG\"], row[\"HEADING\"]]])\n",
    "    # ì‹¤ì œ ì •ë‹µ ë ˆì´ë¸” ì¶”\n",
    "    true_cluster = row[\"CLUSTER_ID\"]\n",
    "    true_port = row[\"PORT_NAME\"]\n",
    "\n",
    "    # ì˜ˆì¸¡ ìˆ˜í–‰ - ìµœì¢… í•­êµ¬ë³„ joint í™•ë¥  ì €ì¥ìš© ë”•ì…”ë„ˆë¦¬\n",
    "    final_probs_joint = {}\n",
    "\n",
    "    # 1ì°¨ ë¶„ë¥˜ê¸° ë¡œë”©\n",
    "    try:\n",
    "        cluster_model = joblib.load(\"./model/cluster_17hours.joblib\")\n",
    "    except:\n",
    "        print(\"âŒ 1ì°¨ êµ°ì§‘ ë¶„ë¥˜ê¸° ë¡œë”© ì‹¤íŒ¨\")\n",
    "        continue\n",
    "\n",
    "    # 1ì°¨ êµ°ì§‘ ì˜ˆì¸¡ ë° Top-2 êµ°ì§‘ ì¶”ì¶œ\n",
    "    cluster_probs = cluster_model.predict_proba(user_input)[0]\n",
    "    cluster_labels = cluster_model.classes_\n",
    "    top2_idx = np.argsort(cluster_probs)[-2:][::-1]\n",
    "\n",
    "    # ê° Top-2 êµ°ì§‘ì— ëŒ€í•´ 2ì°¨ ì˜ˆì¸¡ ìˆ˜í–‰\n",
    "    for idx in top2_idx:\n",
    "        prob_cluster = cluster_probs[idx] # 1ì°¨ ë¶„ë¥˜ê¸°ì—ì„œì˜ êµ°ì§‘ í™•ë¥ \n",
    "        cluster_id = cluster_labels[idx] # í•´ë‹¹ êµ°ì§‘ ë²ˆí˜¸\n",
    "\n",
    "        if cluster_id in fixed_cluster_ports:\n",
    "            fixed_port = fixed_cluster_ports[cluster_id]\n",
    "            final_probs_joint[fixed_port] = final_probs_joint.get(fixed_port, 0) + prob_cluster\n",
    "            continue\n",
    "\n",
    "        if cluster_id not in cluster_model_paths:\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            model = joblib.load(cluster_model_paths[cluster_id][\"model\"])\n",
    "            le = joblib.load(cluster_model_paths[cluster_id][\"encoder\"])\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            port_probs = model.predict_proba(user_input)[0]\n",
    "        except AttributeError:\n",
    "            pred_label = model.predict(user_input)[0]\n",
    "            port_probs = np.zeros(len(le.classes_))\n",
    "            port_probs[pred_label] = 1.0\n",
    "        \n",
    "        port_probs = model.predict_proba(user_input)[0]\n",
    "        try:\n",
    "            port_names = le.inverse_transform(np.arange(len(port_probs)))\n",
    "        except:\n",
    "            port_names = model.classes_\n",
    "\n",
    "        # ê° êµ°ì§‘ ë‚´ì—ì„œ Top-2 í•­êµ¬ë§Œ ì‚¬ìš©\n",
    "        top2_ports_idx = np.argsort(port_probs)[-2:][::-1]\n",
    "        for j in top2_ports_idx:\n",
    "            port = port_names[j]\n",
    "            prob = port_probs[j]\n",
    "            joint_prob = prob_cluster * prob # ğŸ”— Joint í™•ë¥  = êµ°ì§‘í™•ë¥  Ã— í•­êµ¬í™•ë¥ \n",
    "            final_probs_joint[port] = joint_prob\n",
    "\n",
    "    # ì˜ˆì¸¡ í‰ê°€ (joint í™•ë¥ ë¡œ ì •ë ¬ëœ top-3)\n",
    "    if final_probs_joint:\n",
    "        sorted_ports = sorted(final_probs_joint.items(), key=lambda x: x[1], reverse=True)\n",
    "        top3_ports = [p for p, _ in sorted_ports[:3]]\n",
    "\n",
    "        if true_port == top3_ports[0]:\n",
    "            top1_correct += 1\n",
    "        if true_port in top3_ports:\n",
    "            top3_correct += 1\n",
    "\n",
    "# âœ… ìµœì¢… ê²°ê³¼ ì¶œë ¥\n",
    "print(\"\\nğŸ“Š 17ì‹œê°„ í‰ê°€ ê²°ê³¼\")\n",
    "print(f\"ì „ì²´ ìƒ˜í”Œ ìˆ˜: {total}\")\n",
    "print(f\"ğŸ¯ Top-1 ì •í™•ë„: {top1_correct / total:.2%}\")\n",
    "print(f\"ğŸ¯ Top-3 í¬í•¨ë¥ : {top3_correct / total:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de5e3782-69c4-44df-85c4-afeab902ea30",
   "metadata": {},
   "source": [
    "## 1ì°¨ ë¶„ë¥˜ê¸°ì˜ ì •í™•ë„ + top-1 ì •í™•ë„ + top-3 í¬í•¨ë¥ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "568fe508-b757-4d18-9814-5665af9501b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“Š í‰ê°€ ê²°ê³¼\n",
      "ì „ì²´ ìƒ˜í”Œ ìˆ˜: 101\n",
      "ğŸ¯ 1ì°¨ êµ°ì§‘ ì˜ˆì¸¡ ì •í™•ë„ : 70.30%\n",
      "ğŸ¯ 2ì°¨ í•­êµ¬ Top-1 ì •í™•ë„: 41.58%\n",
      "ğŸ¯ 2ì°¨ í•­êµ¬ Top-3 í¬í•¨ë¥ : 63.37%\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# âœ… 1ì°¨/2ì°¨ ëª¨ë¸ ê²½ë¡œ\n",
    "cluster_model_paths = {\n",
    "    1: {\"model\": \"model/port_c1_17hours.joblib\", \"encoder\": \"model/encoder_c1_17hours.joblib\"},\n",
    "    2: {\"model\": \"model/port_c2_17hours.joblib\", \"encoder\": \"model/encoder_c2_17hours.joblib\"},\n",
    "    3: {\"model\": \"model/port_c3_17hours.joblib\", \"encoder\": \"model/encoder_c3_17hours.joblib\"},\n",
    "    4: {\"model\": \"model/port_c4_17hours.joblib\", \"encoder\": \"model/encoder_c4_17hours.joblib\"},\n",
    "    6: {\"model\": \"model/port_c6_17hours.joblib\", \"encoder\": \"model/encoder_c6_17hours.joblib\"},\n",
    "    7: {\"model\": \"model/port_c7_17hours.joblib\", \"encoder\": \"model/encoder_c7_17hours.joblib\"}\n",
    "}\n",
    "fixed_cluster_ports = { 0: \"PHMNL\", 5: \"VNHPH\" }\n",
    "\n",
    "# âœ… cluster_model ë¶ˆëŸ¬ì˜¤ê¸° (1ì°¨ soft voting ëª¨ë¸)\n",
    "cluster_model = joblib.load(\"model/cluster_17hours.joblib\")\n",
    "\n",
    "# âœ… ë°ì´í„° ë¡œë”© (CSV: LAT, LON, COG, HEADING, CLUSTER_ID, PORT_NAME)\n",
    "df = pd.read_csv(\"test_17h_datasets.csv\")\n",
    "\n",
    "# âœ… ì €ì¥ìš© ë¦¬ìŠ¤íŠ¸\n",
    "top1_correct, top3_correct, total = 0, 0, 0\n",
    "cluster_correct = 0  # 1ì°¨ ë¶„ë¥˜ê¸° ì •í™•ë„ìš©\n",
    "\n",
    "for i, row in df.iterrows():\n",
    "    x_input = np.array([[row[\"LAT\"], row[\"LON\"], row[\"COG\"], row[\"HEADING\"]]])\n",
    "    true_cluster = row[\"CLUSTER_ID\"]\n",
    "    true_port = row[\"PORT_NAME\"]\n",
    "\n",
    "    # 1ì°¨ êµ°ì§‘ ì˜ˆì¸¡\n",
    "    cluster_probs = cluster_model.predict_proba(x_input)[0]\n",
    "    cluster_labels = cluster_model.classes_\n",
    "    pred_cluster = cluster_labels[np.argmax(cluster_probs)]\n",
    "\n",
    "    if pred_cluster == true_cluster:\n",
    "        cluster_correct += 1\n",
    "\n",
    "    # Top-2 êµ°ì§‘ ì¶”ì¶œ\n",
    "    top2_idx = np.argsort(cluster_probs)[-2:][::-1]\n",
    "    final_probs_joint = {}\n",
    "\n",
    "    for idx in top2_idx:\n",
    "        cluster_id = cluster_labels[idx]\n",
    "        p_cluster = cluster_probs[idx]\n",
    "\n",
    "        # ê³ ì • í•­êµ¬ ì²˜ë¦¬\n",
    "        if cluster_id in fixed_cluster_ports:\n",
    "            port = fixed_cluster_ports[cluster_id]\n",
    "            final_probs_joint[port] = final_probs_joint.get(port, 0) + p_cluster\n",
    "            continue\n",
    "\n",
    "        # ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "        if cluster_id not in cluster_model_paths:\n",
    "            continue\n",
    "        try:\n",
    "            model = joblib.load(cluster_model_paths[cluster_id][\"model\"])\n",
    "            le = joblib.load(cluster_model_paths[cluster_id][\"encoder\"])\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "        # 2ì°¨ í•­êµ¬ ì˜ˆì¸¡ í™•ë¥ \n",
    "        port_probs = model.predict_proba(x_input)[0]\n",
    "        try:\n",
    "            port_names = le.inverse_transform(np.arange(len(port_probs)))\n",
    "        except:\n",
    "            port_names = model.classes_\n",
    "\n",
    "        top2_ports_idx = np.argsort(port_probs)[-2:][::-1]\n",
    "        for j in top2_ports_idx:\n",
    "            port = port_names[j]\n",
    "            prob = port_probs[j]\n",
    "            joint_prob = p_cluster * prob\n",
    "            final_probs_joint[port] = joint_prob\n",
    "\n",
    "    if not final_probs_joint:\n",
    "        continue\n",
    "\n",
    "    # Top-3 í•­êµ¬ ì˜ˆì¸¡ ê²°ê³¼\n",
    "    sorted_ports = sorted(final_probs_joint.items(), key=lambda x: x[1], reverse=True)\n",
    "    top3_ports = [port for port, _ in sorted_ports[:3]]\n",
    "    top1_port = top3_ports[0]\n",
    "\n",
    "    # ì •í™•ë„ ê³„ì‚°\n",
    "    total += 1\n",
    "    if true_port == top1_port:\n",
    "        top1_correct += 1\n",
    "    if true_port in top3_ports:\n",
    "        top3_correct += 1\n",
    "\n",
    "# âœ… ìµœì¢… ê²°ê³¼ ì¶œë ¥\n",
    "print(\"\\nğŸ“Š í‰ê°€ ê²°ê³¼\")\n",
    "print(f\"ì „ì²´ ìƒ˜í”Œ ìˆ˜: {total}\")\n",
    "print(f\"ğŸ¯ 1ì°¨ êµ°ì§‘ ì˜ˆì¸¡ ì •í™•ë„ : {cluster_correct/total:.2%}\")\n",
    "print(f\"ğŸ¯ 2ì°¨ í•­êµ¬ Top-1 ì •í™•ë„: {top1_correct/total:.2%}\")\n",
    "print(f\"ğŸ¯ 2ì°¨ í•­êµ¬ Top-3 í¬í•¨ë¥ : {top3_correct/total:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9010ba94-05e8-411b-8946-a8d4321840ab",
   "metadata": {},
   "source": [
    "# í…ŒìŠ¤íŠ¸ ë°ì´í„°ë¡œ êµ°ì§‘ë³„ ì •í™•ë„ í™•ì¸í•˜ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "b303fe25-d3ca-4cd0-85df-941a6371ab9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " CLUSTER_ID  ìƒ˜í”Œ ìˆ˜  1ì°¨ êµ°ì§‘ ì •í™•ë„  Top-1 í•­êµ¬ ì •í™•ë„  Top-3 í•­êµ¬ í¬í•¨ë¥ \n",
      "          1    24   0.000000      0.000000      0.000000\n",
      "          2    19   0.842105      0.473684      0.842105\n",
      "          3    28   1.000000      0.750000      0.964286\n",
      "          4     7   1.000000      0.000000      0.857143\n",
      "          6    18   0.833333      0.444444      0.555556\n",
      "          7     5   1.000000      0.800000      1.000000\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "from collections import defaultdict\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# âœ… 1ì°¨/2ì°¨ ëª¨ë¸ ê²½ë¡œ\n",
    "cluster_model_paths = {\n",
    "    1: {\"model\": \"model/port_c1_17hours.joblib\", \"encoder\": \"model/encoder_c1_17hours.joblib\"},\n",
    "    2: {\"model\": \"model/port_c2_17hours.joblib\", \"encoder\": \"model/encoder_c2_17hours.joblib\"},\n",
    "    3: {\"model\": \"model/port_c3_17hours.joblib\", \"encoder\": \"model/encoder_c3_17hours.joblib\"},\n",
    "    4: {\"model\": \"model/port_c4_17hours.joblib\", \"encoder\": \"model/encoder_c4_17hours.joblib\"},\n",
    "    6: {\"model\": \"model/port_c6_17hours.joblib\", \"encoder\": \"model/encoder_c6_17hours.joblib\"},\n",
    "    7: {\"model\": \"model/port_c7_17hours.joblib\", \"encoder\": \"model/encoder_c7_17hours.joblib\"}\n",
    "}\n",
    "fixed_cluster_ports = { 0: \"PHMNL\", 5: \"VNHPH\" }\n",
    "\n",
    "# âœ… ëª¨ë¸ & ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "cluster_model = joblib.load(\"model/cluster_17hours.joblib\")\n",
    "df = pd.read_csv(\"test_17h_datasets.csv\")\n",
    "\n",
    "# âœ… ì „ì²´ ì •í™•ë„ ë³€ìˆ˜\n",
    "top1_correct, top3_correct, total = 0, 0, 0\n",
    "cluster_correct = 0\n",
    "\n",
    "# âœ… êµ°ì§‘ë³„ ì •í™•ë„ ì €ì¥ìš©\n",
    "cluster_stats = defaultdict(lambda: {\n",
    "    \"total\": 0,\n",
    "    \"cluster_correct\": 0,\n",
    "    \"top1_correct\": 0,\n",
    "    \"top3_correct\": 0\n",
    "})\n",
    "\n",
    "# âœ… ì˜ˆì¸¡ ë£¨í”„\n",
    "for _, row in df.iterrows():\n",
    "    x_input = np.array([[row[\"LAT\"], row[\"LON\"], row[\"COG\"], row[\"HEADING\"]]])\n",
    "    true_cluster = row[\"CLUSTER_ID\"]\n",
    "    true_port = row[\"PORT_NAME\"]\n",
    "\n",
    "    cluster_probs = cluster_model.predict_proba(x_input)[0]\n",
    "    cluster_labels = cluster_model.classes_\n",
    "    pred_cluster = cluster_labels[np.argmax(cluster_probs)]\n",
    "\n",
    "    total += 1\n",
    "    cluster_stats[true_cluster][\"total\"] += 1\n",
    "\n",
    "    if pred_cluster == true_cluster:\n",
    "        cluster_correct += 1\n",
    "        cluster_stats[true_cluster][\"cluster_correct\"] += 1\n",
    "\n",
    "    top2_idx = np.argsort(cluster_probs)[-2:][::-1]\n",
    "    final_probs_joint = {}\n",
    "\n",
    "    for idx in top2_idx:\n",
    "        cluster_id = cluster_labels[idx]\n",
    "        p_cluster = cluster_probs[idx]\n",
    "\n",
    "        if cluster_id in fixed_cluster_ports:\n",
    "            port = fixed_cluster_ports[cluster_id]\n",
    "            final_probs_joint[port] = final_probs_joint.get(port, 0) + p_cluster\n",
    "            continue\n",
    "\n",
    "        if cluster_id not in cluster_model_paths:\n",
    "            continue\n",
    "\n",
    "        model = joblib.load(cluster_model_paths[cluster_id][\"model\"])\n",
    "        le = joblib.load(cluster_model_paths[cluster_id][\"encoder\"])\n",
    "        port_probs = model.predict_proba(x_input)[0]\n",
    "\n",
    "        try:\n",
    "            port_names = le.inverse_transform(np.arange(len(port_probs)))\n",
    "        except:\n",
    "            port_names = model.classes_\n",
    "\n",
    "        top2_ports_idx = np.argsort(port_probs)[-2:][::-1]\n",
    "        for j in top2_ports_idx:\n",
    "            port = port_names[j]\n",
    "            prob = port_probs[j]\n",
    "            joint_prob = p_cluster * prob\n",
    "            final_probs_joint[port] = joint_prob\n",
    "\n",
    "    if not final_probs_joint:\n",
    "        continue\n",
    "\n",
    "    sorted_ports = sorted(final_probs_joint.items(), key=lambda x: x[1], reverse=True)\n",
    "    top3_ports = [port for port, _ in sorted_ports[:3]]\n",
    "    top1_port = top3_ports[0]\n",
    "\n",
    "    if true_port == top1_port:\n",
    "        top1_correct += 1\n",
    "        cluster_stats[true_cluster][\"top1_correct\"] += 1\n",
    "    if true_port in top3_ports:\n",
    "        top3_correct += 1\n",
    "        cluster_stats[true_cluster][\"top3_correct\"] += 1\n",
    "\n",
    "# âœ… êµ°ì§‘ë³„ ì •í™•ë„ ì •ë¦¬\n",
    "result = []\n",
    "for cluster_id in sorted(cluster_stats.keys()):\n",
    "    stats = cluster_stats[cluster_id]\n",
    "    total_samples = stats[\"total\"]\n",
    "    result.append({\n",
    "        \"CLUSTER_ID\": cluster_id,\n",
    "        \"ìƒ˜í”Œ ìˆ˜\": total_samples,\n",
    "        \"1ì°¨ êµ°ì§‘ ì •í™•ë„\": stats[\"cluster_correct\"] / total_samples if total_samples else 0,\n",
    "        \"Top-1 í•­êµ¬ ì •í™•ë„\": stats[\"top1_correct\"] / total_samples if total_samples else 0,\n",
    "        \"Top-3 í•­êµ¬ í¬í•¨ë¥ \": stats[\"top3_correct\"] / total_samples if total_samples else 0,\n",
    "    })\n",
    "\n",
    "# âœ… ì¶œë ¥\n",
    "result_df = pd.DataFrame(result)\n",
    "print(result_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a023214d-6287-4abe-b654-5854676221ce",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'predict_top_ports_from_array' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 17\u001b[0m\n\u001b[0;32m     13\u001b[0m true_port \u001b[38;5;241m=\u001b[39m y_test[i]\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m#true_cluster = cluster_ids[i]\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# ì˜ˆì¸¡ ì‹¤í–‰\u001b[39;00m\n\u001b[1;32m---> 17\u001b[0m pred_result, pred_cluster \u001b[38;5;241m=\u001b[39m predict_top_ports_from_array(input_sample)\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# 1. ì˜ˆì¸¡ ê²°ê³¼ê°€ ì¡´ì¬í•  ê²½ìš°ë§Œ ì¶œë ¥\u001b[39;00m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pred_result:\n",
      "\u001b[1;31mNameError\u001b[0m: name 'predict_top_ports_from_array' is not defined"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "num = 3 #ì´ê±¸ ìˆ˜ì •\n",
    "# 1. npy íŒŒì¼ ë¶ˆëŸ¬ì˜¤ê¸° (êµ°ì§‘ 1 ì˜ˆì‹œ)\n",
    "X_test = np.load(f\"./datasets/X_test_c{num}_14hours.npy\")\n",
    "y_test = np.load(f\"./datasets/y_test_c{num}_14hours.npy\", allow_pickle=True)\n",
    "#cluster_ids = np.load(f\"./test datasets/cluster_ids_cluster{num}.npy\")\n",
    "\n",
    "# 2. ì‚¬ìš©í•  ìƒ˜í”Œ ì„ íƒ (ì˜ˆ: 0ë²ˆì§¸)\n",
    "# ìƒ˜í”Œ ì„ íƒ\n",
    "i = 10\n",
    "input_sample = X_test[i].reshape(1, -1)\n",
    "true_port = y_test[i]\n",
    "#true_cluster = cluster_ids[i]\n",
    "\n",
    "# ì˜ˆì¸¡ ì‹¤í–‰\n",
    "pred_result, pred_cluster = predict_top_ports_from_array(input_sample)\n",
    "\n",
    "# 1. ì˜ˆì¸¡ ê²°ê³¼ê°€ ì¡´ì¬í•  ê²½ìš°ë§Œ ì¶œë ¥\n",
    "if pred_result:\n",
    "    print(f\"\\nğŸ“Œ [ìƒ˜í”Œ {i}] ì˜ˆì¸¡ ê²°ê³¼ ìš”ì•½\")\n",
    "\n",
    "    # ì‹¤ì œ êµ°ì§‘ vs ì˜ˆì¸¡ êµ°ì§‘\n",
    "    print(f\"âœ… ì‹¤ì œ ì„ ë°•ì´ ì†í•œ êµ°ì§‘ ë²ˆí˜¸ (ì •ë‹µ): {num}\")\n",
    "    print(f\"âœ… ì˜ˆì¸¡ëœ êµ°ì§‘ ë²ˆí˜¸ (1ì°¨ ë¶„ë¥˜ê¸° ê²°ê³¼): {pred_cluster}\")\n",
    "\n",
    "    # ì˜ˆì¸¡ëœ í•­êµ¬ Top-3 ì¶œë ¥\n",
    "    print(\"\\nğŸ”® [2ì°¨ ë¶„ë¥˜ê¸°] ì˜ˆì¸¡ëœ í•­êµ¬ Top-3 (joint í™•ë¥  ê¸°ì¤€):\")\n",
    "    for rank, (port, prob) in enumerate(pred_result.items(), 1):\n",
    "        print(f\"  {rank}. ğŸ“¦ {port} â†’ {prob:.2%}\")\n",
    "\n",
    "    # Top-3 í•­êµ¬ í›„ë³´ ëª©ë¡\n",
    "    top3 = list(pred_result.keys())\n",
    "\n",
    "    # í‰ê°€ ê²°ê³¼\n",
    "    print(\"\\nğŸ¯ í‰ê°€ ê²°ê³¼:\")\n",
    "\n",
    "    # 1ì°¨ êµ°ì§‘ ì˜ˆì¸¡ì´ ë§ì•˜ëŠ”ê°€?\n",
    "    if pred_cluster == num:\n",
    "        print(\"âœ… [1ì°¨ êµ°ì§‘ ì˜ˆì¸¡] ì •í™•í•˜ê²Œ ë§ì·„ìŠµë‹ˆë‹¤! ğŸ¯\")\n",
    "    else:\n",
    "        print(\"âŒ [1ì°¨ êµ°ì§‘ ì˜ˆì¸¡] êµ°ì§‘ ë²ˆí˜¸ê°€ í‹€ë ¸ìŠµë‹ˆë‹¤. ğŸ’¥\")\n",
    "\n",
    "    # 2ì°¨ í•­êµ¬ ì˜ˆì¸¡ì´ Top-3 ì•ˆì— ì‹¤ì œê°’ í¬í•¨ë˜ì—ˆëŠ”ê°€?\n",
    "    if num in top3:\n",
    "        print(\"âœ… [2ì°¨ í•­êµ¬ ì˜ˆì¸¡] ì‹¤ì œ í•­êµ¬ê°€ Top-3 ì•ˆì— í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤! ğŸ›³ï¸\")\n",
    "    else:\n",
    "        print(\"âŒ [2ì°¨ í•­êµ¬ ì˜ˆì¸¡] Top-3 ì•ˆì— ì‹¤ì œ í•­êµ¬ê°€ ì—†ìŠµë‹ˆë‹¤. âŒ\")\n",
    "\n",
    "else:\n",
    "    print(\"â— ì˜ˆì¸¡ ì‹¤íŒ¨: joint í™•ë¥  ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤ (ëª¨ë¸ ì˜ˆì¸¡ ì‹¤íŒ¨)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e27eeb2c-6d7c-4c8e-9272-a0ce9d786052",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
